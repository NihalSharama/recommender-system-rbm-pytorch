{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M20yVrMxiCEC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel \n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-QRsRypymnnt"
   },
   "outputs": [],
   "source": [
    "# importing the training and testing data\n",
    "training_set = pd.read_csv('data/ml-100k/u1.base', delimiter='\\t')\n",
    "training_set = np.array(training_set, dtype='int')\n",
    "test_set = pd.read_csv('data/ml-100k/u1.test', delimiter='\\t')\n",
    "test_set = np.array(test_set, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3df_rBRprjfm"
   },
   "outputs": [],
   "source": [
    "# getting the max no. of users and movies in data\n",
    "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ImaeTqfw5KiQ"
   },
   "outputs": [],
   "source": [
    "def Df_to_matrix(data):\n",
    "  \"\"\"\n",
    "  it converts the pandas data frame of multiple row of single user_id with single rating to, \n",
    "  a matrix of all ratings of single user in a row with the couloms of movies :)\n",
    "  \"\"\"\n",
    "  matrix = []\n",
    "  for id_user in range(1, nb_users + 1):\n",
    "    id_movies = data[:,1][data[:,0] == id_user]\n",
    "    id_ratings = data[:,2][data[:,0] == id_user]\n",
    "    ratings = np.zeros(nb_movies)\n",
    "    ratings[id_movies - 1] = id_ratings\n",
    "\n",
    "    matrix.append(list(ratings))\n",
    "\n",
    "  return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PPRpglE06uly"
   },
   "outputs": [],
   "source": [
    "training_set = Df_to_matrix(training_set)\n",
    "test_set = Df_to_matrix(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oF4dnksK9S2e"
   },
   "outputs": [],
   "source": [
    "# converting the matrix to float tensors\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "juk3gR4DKV5M"
   },
   "outputs": [],
   "source": [
    "# converting un rated movies with -1\n",
    "training_set[training_set == 0] = -1\n",
    "test_set[test_set == 0] = -1\n",
    "\n",
    "# converting movies rated less then 2 with 0, and more than 2 with 1 \n",
    "training_set[training_set <= 2] = 0\n",
    "test_set[test_set <= 2] = 0\n",
    "\n",
    "training_set[training_set > 2] = 1\n",
    "test_set[test_set > 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([943, 1682])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    # \n",
    "    \"\"\"\n",
    "    ----> the model maybe look like supervised deep learning model,\n",
    "    but its actually unsupervised deep learning model and bcz its doesn't depend on labels\n",
    "    even the data doesn't have any lables all its doing is working on principles of 2nd law of thermodynamics :)\n",
    "    \n",
    "    \n",
    "    creating RBM model with pytorch\n",
    "    nh - no. of hidden node\n",
    "    nv - no. of vissible node\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nv,nh):\n",
    "        self.W = torch.randn(nh,nv) # initializing random wieghts\n",
    "        self.a = torch.randn(1, nh) # initializing random bias for hidden node\n",
    "        self.b = torch.randn(1, nv) # initializing random bias for vissible node\n",
    "        \n",
    "    def sample_h(self, x):\n",
    "        # activation for hidden node (prediction = input * weights + bias)\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        \n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    \n",
    "    def sample_v(self, y):\n",
    "        # activation for vissible node\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        \n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    \n",
    "    def train(self, v0, vk , ph0, phk):\n",
    "        # function(training) to update the weights and bias each batch and epoch (dependent on how programmer use it)\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "        self.a += torch.sum((ph0 - phk), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = len(training_set[0])\n",
    "nh = 100\n",
    "batch_size = 100\n",
    "\n",
    "rbm = RBM(nv, nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \n",
      " loss: 0.1280605047941208\n",
      "epoch: 2 \n",
      " loss: 0.06509843468666077\n",
      "epoch: 3 \n",
      " loss: 0.06688135862350464\n",
      "epoch: 4 \n",
      " loss: 0.0691465213894844\n",
      "epoch: 5 \n",
      " loss: 0.06941471993923187\n",
      "epoch: 6 \n",
      " loss: 0.0701763778924942\n",
      "epoch: 7 \n",
      " loss: 0.0701446682214737\n",
      "epoch: 8 \n",
      " loss: 0.07044986635446548\n",
      "epoch: 9 \n",
      " loss: 0.0707894042134285\n",
      "epoch: 10 \n",
      " loss: 0.07063020765781403\n"
     ]
    }
   ],
   "source": [
    "# training the data\n",
    "nb_epoch = 10\n",
    "\n",
    "for epoch in range(1 ,nb_epoch + 1): # looping troug epoch\n",
    "    train_loss = 0 \n",
    "    s = 0.\n",
    "    \n",
    "    for user_id in range(0, nb_users - batch_size, batch_size): # looping trough batch\n",
    "        \n",
    "        vk = training_set[user_id:user_id + batch_size] # visible node for activating the model and for geting prediction\n",
    "        v0 = training_set[user_id:user_id + batch_size] # visible node for checking the loss\n",
    "        ph0,_ = rbm.sample_h(v0)\n",
    "        \n",
    "        for k in range(10):\n",
    "            _,hk = rbm.sample_h(vk)\n",
    "            _,vk = rbm.sample_v(hk)\n",
    "            vk[v0<0] = v0[v0<0] # letting the unrated nodes to be same\n",
    "            \n",
    "        phk,_ = rbm.sample_h(vk)\n",
    "        rbm.train(v0,vk,ph0,phk)\n",
    "        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
    "        s += 1.\n",
    "        \n",
    "    print(f'epoch: {epoch} \\n loss: {train_loss/s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.06091321259737015\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "s = 0.\n",
    "\n",
    "for id_user in range(nb_users):\n",
    "    v = training_set[id_user: id_user+1] # visible node for activating the model and to be predict\n",
    "    vt = test_set[id_user: id_user+1] # true visible node\n",
    "    if len(vt[vt >= 0]) > 0:\n",
    "        _,h = rbm.sample_h(v) \n",
    "        _,v = rbm.sample_v(h)\n",
    "    test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "    s += 1.\n",
    "    \n",
    "print(f'test loss: {test_loss/s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(prediction_set):\n",
    "    nb_users_pred_set = int(max(prediction_set[:,0]))\n",
    "    test_loss = 0\n",
    "    s = 0.\n",
    "\n",
    "    for id_user in range(nb_users_pred_set):\n",
    "        v = training_set[id_user: id_user+1] # predicting visible node\n",
    "        vt = test_set[id_user: id_user+1] \n",
    "        if len(vt[vt >= 0]) > 0:\n",
    "            _,h = rbm.sample_h(v)\n",
    "            _,v = rbm.sample_v(h)\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "        s += 1.\n",
    "    \n",
    "    print(f'prediction is: {v}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: there are 1682 movies each users should have aligned in rows with there user_id,movie_id and the ratings. then the matrix of it is ready to predicte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "recomender sys(restricted boltzman machine).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
